{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** TEAM NOTES ***\n",
    "- be sure to update all code segements at the very end before submitting to ensure it's the most recent code pushed to GH\n",
    "\n",
    "ENEL 645 Assignment 2\n",
    "Animal Image Classification Model\n",
    "Objectives Learned:\n",
    "    - transfer learning using YoloV5 trained on Coco image dataset\n",
    "    - implementation of convolutional neural networks (CNNs) using Pytorch\n",
    "    - one-hot encoding\n",
    "    - train validation test methods\n",
    "Group 27:\n",
    "    - Jose Eustaquio do Carmo Junior\n",
    "    - Louis-Antoine Etchian\n",
    "    - Michael Francis\n",
    "    - Austyn Nagribiano\n",
    "    - Peter Yuan\n",
    "    - Mouri Zakir\n",
    "\n",
    "CONTENTS\n",
    "1. Introduction\n",
    "2. data\n",
    "3. ...\n",
    "\n",
    "\n",
    "This project uses an animal classification dataset (https://www.kaggle.com/datasets/ashishsaxena2209/animal-image-datasetdog-cat-and-panda) with three classifiers: cats, dogs, pandas. The imageset contains 3000 labelled images evenly split between each of the three classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importing libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Getting data statistics:\n",
    "\n",
    "'get_data_statistics()' returns the mean and standard deviation of the dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def get_dataset_stats(data_loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    nb_samples = 0.\n",
    "    for data in data_loader:\n",
    "        data = data[0]  # Get the images to compute the stgatistics\n",
    "        batch_samples = data.size(0)\n",
    "        data = data.view(batch_samples, data.size(1), -1)\n",
    "        mean += data.mean(2).sum(0)\n",
    "        std += data.std(2).sum(0)\n",
    "        nb_samples += batch_samples\n",
    "\n",
    "    mean /= nb_samples\n",
    "    std /= nb_samples\n",
    "    return mean, std"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defining a custom class for use with PyTorch framework:\n",
    "\n",
    "'TorchVisionDataset()' is a custom dataset class to be used within the PyTorch framework. It inherits the 'Dataset' class from PyTorch and takes in two arguments: 'data_dic' and 'transform'. 'data_dic' is a dictionary with two keys each for the imageset and labels. 'transform' applies a specific transformation to the dataset with the default set to none.\n",
    "\n",
    "Two methods are defined for this class: '__len__' and '__getitem__'. '__len__' returns the length of the imageset or the total number of samples. '__getitem__' is the main functionality for this class and returns the image and label for a defined index ('idx') input as the argument. The image is extracted from the dataset filepath and if a transform is specified, applied to the image before returning with the label."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class TorchVisionDataset(Dataset):\n",
    "    def __init__(self, data_dic, transform=None):\n",
    "        self.file_paths = data_dic[\"X\"]\n",
    "        self.labels = data_dic[\"Y\"]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        file_path = self.file_paths[idx]\n",
    "\n",
    "        image = Image.open(file_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defining the model:\n",
    "\n",
    "AnimalModel defines the model framework for the convolutional neural network (CNN). The mode takes in the number of classes, input shape of data, and a transfer learning flag as inputs. If transfer learning is activated, as in this project, the model obtains pre-trained weights from 'YoloV5' and freezes the validation layers.\n",
    "\n",
    "Two methods are defined for this class: '_get_conv_output()' and 'forward()'. '_get_conv_output()' returns the number of features from the feature extractor, useful in initializing the final fully connected classification layer. 'forward()' makes the final pass of the data to the output. It applies the feature extractor to the input data, flattens, and then applies the final linear activation to classify the image."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "class GarbageModel(nn.Module):\n",
    "    def __init__(self, num_classes, input_shape, transfer=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.transfer = transfer\n",
    "        self.num_classes = num_classes\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "        # transfer learning if pretrained=True\n",
    "        self.feature_extractor = models.resnet18(pretrained=transfer)\n",
    "\n",
    "        if self.transfer:\n",
    "            # layers are frozen by using eval()\n",
    "            self.feature_extractor.eval()\n",
    "            # freeze params\n",
    "            for param in self.feature_extractor.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        n_features = self._get_conv_output(self.input_shape)\n",
    "        self.classifier = nn.Linear(n_features, num_classes)\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        batch_size = 1\n",
    "        tmp_input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
    "\n",
    "        output_feat = self.feature_extractor(tmp_input)\n",
    "        n_size = output_feat.data.view(batch_size, -1).size(1)\n",
    "        return n_size\n",
    "\n",
    "    # will be used during inference\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "loading data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def get_data_loaders(images_path, val_split, test_split, batch_size=32, verbose=True):\n",
    "    \"\"\"\n",
    "    These function generates the data loaders for our problem. It assumes paths are\n",
    "    defined by \"/\" and image files are jpg. Each subfolder in the images_path\n",
    "    represents a different class.\n",
    "\n",
    "    Args:\n",
    "        images_path (_type_): Path to folders containing images of each class.\n",
    "        val_split (_type_): percentage of data to be used in the val set\n",
    "        test_split (_type_): percentage of data to be used in the val set\n",
    "        verbose (_type_): debug flag\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: Train, validation and test data laoders.\n",
    "    \"\"\"\n",
    "\n",
    "    # Listing the data\n",
    "    # Cats\n",
    "    print(\"LISTING DATA\")\n",
    "    # print(os.listdir(\"dataset\"))\n",
    "    input_dir = \"dataset/temp/cats\"\n",
    "    # images = [Image.open(os.path.join(input_dir, image)) for image in os.listdir(input_dir)]  # load\n",
    "    images = [os.path.join(input_dir, image) for image in os.listdir(input_dir)]\n",
    "    cat_images = np.array(images)  # transform to numpy\n",
    "    cat_labels = ['cat'] * len(cat_images)\n",
    "\n",
    "    # Dogs\n",
    "    input_dir2 = \"dataset/temp/dogs\"\n",
    "    # images2 = [Image.open(os.path.join(input_dir2, image)) for image in os.listdir(input_dir2)]  # load\n",
    "    images2 = [os.path.join(input_dir2, image) for image in os.listdir(input_dir2)]\n",
    "    dog_images = np.array(images2)  # transform to numpy\n",
    "    dog_labels = ['dog'] * len(dog_images)\n",
    "\n",
    "    # Panda\n",
    "    input_dir3 = \"dataset/temp/panda\"\n",
    "    # images3 = [Image.open(os.path.join(input_dir3, image)) for image in os.listdir(input_dir3)]  # load\n",
    "    images3 = [os.path.join(input_dir3, image) for image in os.listdir(input_dir3)]\n",
    "    panda_images = np.array(images3)  # transform to numpy\n",
    "    panda_labels = ['panda'] * len(panda_images)\n",
    "\n",
    "    # Appending lists\n",
    "    images = np.append(np.append(cat_images, dog_images), panda_images)\n",
    "    labels = cat_labels + dog_labels + panda_labels\n",
    "    print(len(labels))\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Formatting the labs as ints\n",
    "    classes = np.unique(labels).flatten()\n",
    "    labels_int = np.zeros(labels.size, dtype=np.int64)\n",
    "\n",
    "    # Convert string labels to integers\n",
    "    for index, class_name in enumerate(classes):\n",
    "        labels_int[labels == class_name] = index\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Number of images in the dataset:\", len(images))\n",
    "        for index, class_name in enumerate(classes):\n",
    "            print(\"Number of images in class \", class_name,\n",
    "                  \":\", (labels_int == index).sum())\n",
    "\n",
    "    # Splitting the data in dev and test sets\n",
    "    sss = StratifiedShuffleSplit(\n",
    "        n_splits=1, test_size=test_split, random_state=10)\n",
    "    sss.get_n_splits(images, labels_int)\n",
    "    dev_index, test_index = next(sss.split(images, labels_int))\n",
    "\n",
    "    dev_images = images[dev_index]\n",
    "    dev_labels = labels_int[dev_index]\n",
    "\n",
    "    test_images = images[test_index]\n",
    "    test_labels = labels_int[test_index]\n",
    "\n",
    "    # Splitting the data in train and val sets\n",
    "    val_size = int(val_split * images.size)\n",
    "    val_split = val_size / dev_images.size\n",
    "    sss2 = StratifiedShuffleSplit(\n",
    "        n_splits=1, test_size=val_split, random_state=10)\n",
    "    sss2.get_n_splits(dev_images, dev_labels)\n",
    "    train_index, val_index = next(sss2.split(dev_images, dev_labels))\n",
    "\n",
    "    train_images = images[train_index]\n",
    "    train_labels = labels_int[train_index]\n",
    "\n",
    "    val_images = images[val_index]\n",
    "    val_labels = labels_int[val_index]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Train set:\", train_images.size)\n",
    "        # print(train_labels)\n",
    "        print(\"Val set:\", val_images.size)\n",
    "        # print(val_labels)\n",
    "        print(\"Test set:\", test_images.size)\n",
    "        # print(test_labels)\n",
    "\n",
    "    # Representing the sets as dictionaries\n",
    "    train_set = {\"X\": train_images, \"Y\": train_labels}\n",
    "    val_set = {\"X\": val_images, \"Y\": val_labels}\n",
    "    test_set = {\"X\": test_images, \"Y\": test_labels}\n",
    "\n",
    "    # Transforms\n",
    "    torchvision_transform_train = transforms.Compose([transforms.Resize((640, 640)),\n",
    "                                                      transforms.RandomHorizontalFlip(),\n",
    "                                                      transforms.RandomVerticalFlip(),\n",
    "                                                      transforms.ToTensor()])\n",
    "\n",
    "    # Datasets\n",
    "    train_dataset_unorm = TorchVisionDataset(\n",
    "        train_set, transform=torchvision_transform_train)\n",
    "\n",
    "    # Get training set stats\n",
    "    trainloader_unorm = torch.utils.data.DataLoader(\n",
    "        train_dataset_unorm, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    mean_train, std_train = get_dataset_stats(trainloader_unorm)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Statistics of training set\")\n",
    "        print(\"Mean:\", mean_train)\n",
    "        print(\"Std:\", std_train)\n",
    "\n",
    "    torchvision_transform = transforms.Compose([transforms.Resize((640, 640)),\n",
    "                                                transforms.RandomHorizontalFlip(), transforms.RandomVerticalFlip(),\n",
    "                                                transforms.ToTensor(),\n",
    "                                                transforms.Normalize(mean=mean_train, std=std_train)])\n",
    "\n",
    "    torchvision_transform_test = transforms.Compose([transforms.Resize((640, 640)),\n",
    "                                                     transforms.ToTensor(),\n",
    "                                                     transforms.Normalize(mean=mean_train, std=std_train)])\n",
    "\n",
    "    # Get the train/val/test loaders\n",
    "    train_dataset = TorchVisionDataset(\n",
    "        train_set, transform=torchvision_transform)\n",
    "    val_dataset = TorchVisionDataset(val_set, transform=torchvision_transform)\n",
    "    test_dataset = TorchVisionDataset(\n",
    "        test_set, transform=torchvision_transform_test)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    valloader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, num_workers=0)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "    return trainloader, valloader, testloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train and validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def train_validate(net, trainloader, valloader, epochs, batch_size,\n",
    "                   learning_rate, best_model_path, device, verbose):\n",
    "    best_loss = 1e+20\n",
    "    for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "        # Loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()  # Loss function\n",
    "        optimizer = torch.optim.AdamW(net.parameters(), lr=learning_rate)\n",
    "        scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "        # Training Loop\n",
    "        train_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "        print(f'{20 + 1},  train loss: {train_loss / i:.3f},', end=' ')\n",
    "        scheduler.step()\n",
    "\n",
    "        val_loss = 0\n",
    "        # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(valloader, 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "            print(f'val loss: {val_loss / i:.3f}')\n",
    "\n",
    "            # Save best model\n",
    "            if val_loss < best_loss:\n",
    "                print(\"Saving model\")\n",
    "                torch.save(net.state_dict(), best_model_path)\n",
    "                best_loss = val_loss\n",
    "\n",
    "    print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def test(net, testloader, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print(len(testloader))\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            print(\"images:\")\n",
    "            print(images[0].size())\n",
    "            print(images[0].permute(1,2,0))\n",
    "            image = torch.Tensor.cpu(images[0])\n",
    "            plt.imshow(image.permute(1,2,0))\n",
    "            print(\"labels:\")\n",
    "            print(labels)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            print(\"predicted:\")\n",
    "            print(predicted)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "    print(\n",
    "        f'Accuracy of the network on the test images: {100 * correct / total} %')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Main"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--learning_rate', type=float, default=1e-4, help='initial learning rate')\n",
    "    parser.add_argument('--batch_size', type=int, default=1, help='batch size,  number of images in each iteration during training')\n",
    "    parser.add_argument('--epochs', type=int, default=20, help='total epochs')\n",
    "    parser.add_argument('--val_split', type=float, default=0.2, help='val split')\n",
    "    parser.add_argument('--test_split', type=float, default=0.2, help='test split')\n",
    "    parser.add_argument('--best_model_path', type=str, default=\"best_model\", help='best model path')\n",
    "    parser.add_argument('--images_path', type=str, default=1e-4, help='path to images')\n",
    "    parser.add_argument('--verbose', type=bool, default=True, help='verbose debugging flag')\n",
    "    parser.add_argument('--transfer_learning', type=bool, default=True, help='transfer learning flag')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Check if GPU is available\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "    if args.verbose:\n",
    "      print(device)\n",
    "\n",
    "    trainloader, valloader, testloader = \\\n",
    "    get_data_loaders(args.images_path, args.val_split, args.test_split,\\\n",
    "                     batch_size=args.batch_size, verbose=args.verbose)\n",
    "\n",
    "\n",
    "    # Create our model\n",
    "    net = GarbageModel(3, (3,640,640), args.transfer_learning)\n",
    "    net.to(device)\n",
    "\n",
    "    train_validate(net, trainloader, valloader, args.epochs, args.batch_size,\\\n",
    "         args.learning_rate, args.best_model_path, device, args.verbose)\n",
    "\n",
    "    net.load_state_dict(torch.load(args.best_model_path))\n",
    "\n",
    "    test(net, testloader,device)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
