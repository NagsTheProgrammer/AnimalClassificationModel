{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - ENEL-645"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** TEAM NOTES ***\n",
    "- be sure to update all code segements at the very end before submitting to ensure it's the most recent code pushed to GH\n",
    "\n",
    "ENEL 645 Assignment 2\n",
    "Animal Image Classification Model\n",
    "Objectives Learned:\n",
    "    - transfer learning using DenseNet trained on image net dataset\n",
    "    - implementation of convolutional neural networks (CNNs) using Pytorch\n",
    "    - one-hot encoding\n",
    "    - train validation test methods\n",
    "Group 27:\n",
    "    - Jose Eustaquio do Carmo Junior\n",
    "    - Louis-Antoine Etchian\n",
    "    - Michael Francis\n",
    "    - Austyn Nagribiano\n",
    "    - Peter Yuan\n",
    "    - Mouri Zakir\n",
    "\n",
    "CONTENTS\n",
    "1. Introduction\n",
    "2. data\n",
    "3. ...\n",
    "\n",
    "\n",
    "This project uses an animal classification dataset (https://www.kaggle.com/datasets/ashishsaxena2209/animal-image-datasetdog-cat-and-panda) with three classifiers: cats, dogs, pandas. The imageset contains 3000 labelled images evenly split between each of the three classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms, models\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCustomDataset\u001b[39;00m(\u001b[43mDataset\u001b[49m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_paths, labels, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_paths \u001b[38;5;241m=\u001b[39m file_paths\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        file_path = self.file_paths[idx]\n",
    "\n",
    "        image = Image.open(file_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom nn Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAnimalModel\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_classes, input_shape, transfer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class AnimalModel(nn.Module):\n",
    "    def __init__(self, num_classes, input_shape, transfer=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.transfer = transfer\n",
    "        self.num_classes = num_classes\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "        # transfer learning if pretrained=True\n",
    "        self.feature_extractor = models.densenet161(pretrained=transfer)\n",
    "\n",
    "        if self.transfer:\n",
    "            # layers are frozen by using eval()\n",
    "            self.feature_extractor.eval()\n",
    "            # freeze params\n",
    "            for param in self.feature_extractor.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        n_features = self._get_conv_output(self.input_shape)\n",
    "        self.classifier = nn.Linear(n_features, num_classes)\n",
    "        \n",
    "    def _get_conv_output(self, shape):\n",
    "        batch_size = 1\n",
    "        tmp_input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
    "\n",
    "        output_feat = self.feature_extractor(tmp_input)\n",
    "        n_size = output_feat.data.view(batch_size, -1).size(1)\n",
    "        return n_size\n",
    "\n",
    "    # will be used during inference\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader generation convenience function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(val_split, test_split, batch_size=32, verbose=True):\n",
    "    num_workers = 0\n",
    "    random_state = 10\n",
    "    n_splits = 1\n",
    "\n",
    "    # Listing the data\n",
    "    # Cats\n",
    "    print(\"LISTING DATA\")\n",
    "    input_dir = \"dataset/temp/cats\"\n",
    "    images = [os.path.join(input_dir, image) for image in os.listdir(input_dir)]\n",
    "    cat_images = np.array(images)  # transform to numpy\n",
    "    cat_labels = ['cat'] * len(cat_images)\n",
    "\n",
    "    # Dogs\n",
    "    input_dir2 = \"dataset/temp/dogs\"\n",
    "    images2 = [os.path.join(input_dir2, image) for image in os.listdir(input_dir2)]\n",
    "    dog_images = np.array(images2)  # transform to numpy\n",
    "    dog_labels = ['dog'] * len(dog_images)\n",
    "\n",
    "    # Panda\n",
    "    input_dir3 = \"dataset/temp/panda\"\n",
    "    images3 = [os.path.join(input_dir3, image) for image in os.listdir(input_dir3)]\n",
    "    panda_images = np.array(images3)  # transform to numpy\n",
    "    panda_labels = ['panda'] * len(panda_images)\n",
    "\n",
    "    # Appending lists\n",
    "    images = np.append(np.append(cat_images, dog_images), panda_images)\n",
    "    labels = cat_labels + dog_labels + panda_labels\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Formatting the labs as ints\n",
    "    classes = np.unique(labels).flatten()\n",
    "    labels_int = np.zeros(labels.size, dtype=np.int64)\n",
    "\n",
    "    # Convert string labels to integers\n",
    "    for index, class_name in enumerate(classes):\n",
    "        labels_int[labels == class_name] = index\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Number of images in the dataset:\", len(images))\n",
    "        for index, class_name in enumerate(classes):\n",
    "            print(\"Number of images in class \", class_name,\n",
    "                  \":\", (labels_int == index).sum())\n",
    "\n",
    "    # Splitting the data in dev and test sets\n",
    "    sss = StratifiedShuffleSplit(\n",
    "        n_splits=n_splits, test_size=test_split, random_state=random_state)\n",
    "    sss.get_n_splits(images, labels_int)\n",
    "    dev_index, test_index = next(sss.split(images, labels_int))\n",
    "\n",
    "    dev_images = images[dev_index]\n",
    "    dev_labels = labels_int[dev_index]\n",
    "\n",
    "    test_images = images[test_index]\n",
    "    test_labels = labels_int[test_index]\n",
    "\n",
    "    # Splitting the data in train and val sets\n",
    "    val_size = int(val_split * images.size)\n",
    "    val_split = val_size / dev_images.size\n",
    "    sss2 = StratifiedShuffleSplit(\n",
    "        n_splits=n_splits, test_size=val_split, random_state=random_state)\n",
    "    sss2.get_n_splits(dev_images, dev_labels)\n",
    "    train_index, val_index = next(sss2.split(dev_images, dev_labels))\n",
    "\n",
    "    train_images = images[train_index]\n",
    "    train_labels = labels_int[train_index]\n",
    "\n",
    "    val_images = images[val_index]\n",
    "    val_labels = labels_int[val_index]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Train set:\", train_images.size)\n",
    "        print(\"Val set:\", val_images.size)\n",
    "        print(\"Test set:\", test_images.size)\n",
    "\n",
    "    # Transforms\n",
    "    torchvision_transform_train = transforms.Compose(\n",
    "        [transforms.Resize((args.unified_image_width, args.unified_image_height)),\n",
    "         transforms.RandomHorizontalFlip(),\n",
    "         transforms.RandomVerticalFlip(),\n",
    "         transforms.ToTensor()])\n",
    "\n",
    "    # Datasets\n",
    "    train_dataset_unorm = CustomDataset(\n",
    "        train_images, train_labels, transform=torchvision_transform_train)\n",
    "\n",
    "    # Get training set stats\n",
    "    trainloader_unorm = torch.utils.data.DataLoader(\n",
    "        train_dataset_unorm, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "    mean_train, std_train = get_dataset_stats(trainloader_unorm)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Statistics of training set\")\n",
    "        print(\"Mean:\", mean_train)\n",
    "        print(\"Std:\", std_train)\n",
    "\n",
    "    torchvision_transform = transforms.Compose(\n",
    "        [transforms.Resize((args.unified_image_width, args.unified_image_height)),\n",
    "         transforms.RandomHorizontalFlip(), transforms.RandomVerticalFlip(),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=mean_train, std=std_train)])\n",
    "\n",
    "    torchvision_transform_test = transforms.Compose(\n",
    "        [transforms.Resize((args.unified_image_width, args.unified_image_height)),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=mean_train, std=std_train)])\n",
    "\n",
    "    # Get the train/val/test loaders\n",
    "    train_dataset = CustomDataset(\n",
    "        train_images, train_labels, transform=torchvision_transform)\n",
    "    val_dataset = CustomDataset(val_images, val_labels, transform=torchvision_transform)\n",
    "    test_dataset = CustomDataset(\n",
    "        test_images, test_labels, transform=torchvision_transform_test)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training convenience function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_with_hyperparameters(observed_model, train_loader, val_loader, epochs,\n",
    "                                        learning_rate, best_model_path, device, patience, verbose):\n",
    "    best_loss = float(\"inf\")\n",
    "    gamma = 0.9\n",
    "    counter = 0\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()  # Loss function\n",
    "    optimizer = torch.optim.AdamW(observed_model.parameters(), lr=learning_rate)\n",
    "    scheduler = ExponentialLR(optimizer, gamma=gamma)\n",
    "\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        # Training Loop\n",
    "        train_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = observed_model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        val_loss = 0\n",
    "        # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(val_loader, 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = observed_model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "            # Save best model\n",
    "            if val_loss < best_loss:\n",
    "                torch.save(observed_model.state_dict(), best_model_path)\n",
    "                best_loss = val_loss\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "                if counter >= patience:\n",
    "                    if verbose:\n",
    "                        print(f'Validation loss has not improved for {patience} epochs. Stopping training.')\n",
    "                    break\n",
    "\n",
    "    return val_loss / (i + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model and hyperparameters convenience function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_hyperparameters_and_train_model(best_model_path, device, verbose, patience):\n",
    "    epochs_range = [10, 20, 30, 40, 50]\n",
    "    batch_size_range = [2, 4, 8, 16, 32, 48, 64]\n",
    "    learning_rate_range = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "\n",
    "    # Perform the grid search\n",
    "    best_val_loss = float('inf')\n",
    "    best_hyperparameters = None\n",
    "\n",
    "    for epochs in epochs_range:\n",
    "        for batch_size in batch_size_range:\n",
    "            for learning_rate in learning_rate_range:\n",
    "                train_loader, val_loader, test_loader = get_data_loaders(args.val_split, args.test_split)\n",
    "                current_model = AnimalModel(args.num_classes,\n",
    "                                            (args.num_classes, args.unified_image_width, args.unified_image_height))\n",
    "                current_model.to(device)\n",
    "                val_loss = train_validate_with_hyperparameters(current_model, train_loader, val_loader, epochs,\n",
    "                                                               learning_rate, best_model_path, device, patience,\n",
    "                                                               verbose)\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_hyperparameters = (epochs, batch_size, learning_rate)\n",
    "                    torch.save(current_model.state_dict(), best_model_path)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Best nbr epochs:\", best_hyperparameters[0])\n",
    "        print(\"Best batch size:\", best_hyperparameters[1])\n",
    "        print(\"Best learning rate:\", best_hyperparameters[2])\n",
    "\n",
    "    return best_hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test convenience function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, testloader, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(\n",
    "        f'Accuracy of the network on the test images: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats generation convenience function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_stats(data_loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    nb_samples = 0.\n",
    "    for data in data_loader:\n",
    "        samples = data[0]\n",
    "        batch_samples = samples.size(0)\n",
    "        samples = samples.view(batch_samples, samples.size(1), -1)\n",
    "        mean += samples.mean(2).sum(0)\n",
    "        std += samples.std(2).sum(0)\n",
    "        nb_samples += batch_samples\n",
    "\n",
    "    mean /= nb_samples\n",
    "    std /= nb_samples\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--learning_rate LEARNING_RATE] [--batch_size BATCH_SIZE] [--epochs EPOCHS]\n",
      "                             [--val_split VAL_SPLIT] [--test_split TEST_SPLIT] [--best_model_path BEST_MODEL_PATH]\n",
      "                             [--verbose VERBOSE] [--transfer_learning TRANSFER_LEARNING] [--num_classes NUM_CLASSES]\n",
      "                             [--unified_image_height UNIFIED_IMAGE_HEIGHT] [--unified_image_width UNIFIED_IMAGE_WIDTH]\n",
      "                             [--patience PATIENCE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\LA\\AppData\\Roaming\\jupyter\\runtime\\kernel-9a066a21-d3c5-4d20-9081-b5ce50f21160.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LA\\anaconda3\\envs\\ensf-ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3377: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--learning_rate', type=float, default=1e-4, help='initial learning rate')\n",
    "parser.add_argument('--batch_size', type=int, default=2, help='batch size,  number of images in each iteration during training')\n",
    "parser.add_argument('--epochs', type=int, default=10, help='total epochs')\n",
    "parser.add_argument('--val_split', type=float, default=0.2, help='val split')\n",
    "parser.add_argument('--test_split', type=float, default=0.2, help='test split')\n",
    "parser.add_argument('--best_model_path', type=str, default=\"best_model\", help='best model path')\n",
    "parser.add_argument('--verbose', type=bool, default=True, help='verbose debugging flag')\n",
    "parser.add_argument('--transfer_learning', type=bool, default=True, help='transfer learning flag')\n",
    "parser.add_argument('--num_classes', type=int, default=3, help='Number of classes in dataset')\n",
    "parser.add_argument('--unified_image_height', type=int, default=224, help='transfer learning flag')\n",
    "parser.add_argument('--unified_image_width', type=int, default=224, help='transfer learning flag')\n",
    "parser.add_argument('--patience', type=int, default=5, help='transfer learning flag')\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChosen device:\u001b[39m\u001b[38;5;124m\"\u001b[39m, device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if args.verbose:\n",
    "    print(\"Chosen device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'define_hyperparameters_and_train_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_batch_size \u001b[38;5;241m=\u001b[39m \u001b[43mdefine_hyperparameters_and_train_model\u001b[49m(args\u001b[38;5;241m.\u001b[39mbest_model_path, device, args\u001b[38;5;241m.\u001b[39mverbose, args\u001b[38;5;241m.\u001b[39mpatience)[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'define_hyperparameters_and_train_model' is not defined"
     ]
    }
   ],
   "source": [
    "best_batch_size = define_hyperparameters_and_train_model(args.best_model_path, device, args.verbose, args.patience)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m get_data_loaders(\u001b[43margs\u001b[49m\u001b[38;5;241m.\u001b[39mval_split, args\u001b[38;5;241m.\u001b[39mtest_split, batch_size\u001b[38;5;241m=\u001b[39mbest_batch_size, verbose\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mverbose)[\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "test_loader = get_data_loaders(args.val_split, args.test_split, batch_size=best_batch_size, verbose=args.verbose)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AnimalModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAnimalModel\u001b[49m(args\u001b[38;5;241m.\u001b[39mnum_classes, (args\u001b[38;5;241m.\u001b[39mnum_classes, args\u001b[38;5;241m.\u001b[39munified_image_width, args\u001b[38;5;241m.\u001b[39munified_image_height))\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(args\u001b[38;5;241m.\u001b[39mbest_model_path))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AnimalModel' is not defined"
     ]
    }
   ],
   "source": [
    "model = AnimalModel(args.num_classes, (args.num_classes, args.unified_image_width, args.unified_image_height))\n",
    "model.load_state_dict(torch.load(args.best_model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test(\u001b[43mmodel\u001b[49m, test_loader, device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "test(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous verison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting data statistics:\n",
    "\n",
    "'get_data_statistics()' returns the mean and standard deviation of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_stats(data_loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    nb_samples = 0.\n",
    "    for data in data_loader:\n",
    "        data = data[0]  # Get the images to compute the stgatistics\n",
    "        batch_samples = data.size(0)\n",
    "        data = data.view(batch_samples, data.size(1), -1)\n",
    "        mean += data.mean(2).sum(0)\n",
    "        std += data.std(2).sum(0)\n",
    "        nb_samples += batch_samples\n",
    "\n",
    "    mean /= nb_samples\n",
    "    std /= nb_samples\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a custom class for use with PyTorch framework:\n",
    "\n",
    "'TorchVisionDataset()' is a custom dataset class to be used within the PyTorch framework. It inherits the 'Dataset' class from PyTorch and takes in two arguments: 'data_dic' and 'transform'. 'data_dic' is a dictionary with two keys each for the imageset and labels. 'transform' applies a specific transformation to the dataset with the default set to none.\n",
    "\n",
    "Two methods are defined for this class: '__len__' and '__getitem__'. '__len__' returns the length of the imageset or the total number of samples. '__getitem__' is the main functionality for this class and returns the image and label for a defined index ('idx') input as the argument. The image is extracted from the dataset filepath and if a transform is specified, applied to the image before returning with the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchVisionDataset(Dataset):\n",
    "    def __init__(self, data_dic, transform=None):\n",
    "        self.file_paths = data_dic[\"X\"]\n",
    "        self.labels = data_dic[\"Y\"]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        file_path = self.file_paths[idx]\n",
    "\n",
    "        image = Image.open(file_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the model:\n",
    "\n",
    "AnimalModel defines the model framework for the convolutional neural network (CNN). The mode takes in the number of classes, input shape of data, and a transfer learning flag as inputs. If transfer learning is activated, as in this project, the model obtains pre-trained weights from 'YoloV5' and freezes the validation layers.\n",
    "\n",
    "Two methods are defined for this class: '_get_conv_output()' and 'forward()'. '_get_conv_output()' returns the number of features from the feature extractor, useful in initializing the final fully connected classification layer. 'forward()' makes the final pass of the data to the output. It applies the feature extractor to the input data, flattens, and then applies the final linear activation to classify the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GarbageModel(nn.Module):\n",
    "    def __init__(self, num_classes, input_shape, transfer=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.transfer = transfer\n",
    "        self.num_classes = num_classes\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "        # transfer learning if pretrained=True\n",
    "        self.feature_extractor = models.resnet18(pretrained=transfer)\n",
    "\n",
    "        if self.transfer:\n",
    "            # layers are frozen by using eval()\n",
    "            self.feature_extractor.eval()\n",
    "            # freeze params\n",
    "            for param in self.feature_extractor.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        n_features = self._get_conv_output(self.input_shape)\n",
    "        self.classifier = nn.Linear(n_features, num_classes)\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        batch_size = 1\n",
    "        tmp_input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
    "\n",
    "        output_feat = self.feature_extractor(tmp_input)\n",
    "        n_size = output_feat.data.view(batch_size, -1).size(1)\n",
    "        return n_size\n",
    "\n",
    "    # will be used during inference\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(images_path, val_split, test_split, batch_size=32, verbose=True):\n",
    "    \"\"\"\n",
    "    These function generates the data loaders for our problem. It assumes paths are\n",
    "    defined by \"/\" and image files are jpg. Each subfolder in the images_path\n",
    "    represents a different class.\n",
    "\n",
    "    Args:\n",
    "        images_path (_type_): Path to folders containing images of each class.\n",
    "        val_split (_type_): percentage of data to be used in the val set\n",
    "        test_split (_type_): percentage of data to be used in the val set\n",
    "        verbose (_type_): debug flag\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: Train, validation and test data laoders.\n",
    "    \"\"\"\n",
    "\n",
    "    # Listing the data\n",
    "    # Cats\n",
    "    print(\"LISTING DATA\")\n",
    "    # print(os.listdir(\"dataset\"))\n",
    "    input_dir = \"dataset/temp/cats\"\n",
    "    # images = [Image.open(os.path.join(input_dir, image)) for image in os.listdir(input_dir)]  # load\n",
    "    images = [os.path.join(input_dir, image) for image in os.listdir(input_dir)]\n",
    "    cat_images = np.array(images)  # transform to numpy\n",
    "    cat_labels = ['cat'] * len(cat_images)\n",
    "\n",
    "    # Dogs\n",
    "    input_dir2 = \"dataset/temp/dogs\"\n",
    "    # images2 = [Image.open(os.path.join(input_dir2, image)) for image in os.listdir(input_dir2)]  # load\n",
    "    images2 = [os.path.join(input_dir2, image) for image in os.listdir(input_dir2)]\n",
    "    dog_images = np.array(images2)  # transform to numpy\n",
    "    dog_labels = ['dog'] * len(dog_images)\n",
    "\n",
    "    # Panda\n",
    "    input_dir3 = \"dataset/temp/panda\"\n",
    "    # images3 = [Image.open(os.path.join(input_dir3, image)) for image in os.listdir(input_dir3)]  # load\n",
    "    images3 = [os.path.join(input_dir3, image) for image in os.listdir(input_dir3)]\n",
    "    panda_images = np.array(images3)  # transform to numpy\n",
    "    panda_labels = ['panda'] * len(panda_images)\n",
    "\n",
    "    # Appending lists\n",
    "    images = np.append(np.append(cat_images, dog_images), panda_images)\n",
    "    labels = cat_labels + dog_labels + panda_labels\n",
    "    print(len(labels))\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Formatting the labs as ints\n",
    "    classes = np.unique(labels).flatten()\n",
    "    labels_int = np.zeros(labels.size, dtype=np.int64)\n",
    "\n",
    "    # Convert string labels to integers\n",
    "    for index, class_name in enumerate(classes):\n",
    "        labels_int[labels == class_name] = index\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Number of images in the dataset:\", len(images))\n",
    "        for index, class_name in enumerate(classes):\n",
    "            print(\"Number of images in class \", class_name,\n",
    "                  \":\", (labels_int == index).sum())\n",
    "\n",
    "    # Splitting the data in dev and test sets\n",
    "    sss = StratifiedShuffleSplit(\n",
    "        n_splits=1, test_size=test_split, random_state=10)\n",
    "    sss.get_n_splits(images, labels_int)\n",
    "    dev_index, test_index = next(sss.split(images, labels_int))\n",
    "\n",
    "    dev_images = images[dev_index]\n",
    "    dev_labels = labels_int[dev_index]\n",
    "\n",
    "    test_images = images[test_index]\n",
    "    test_labels = labels_int[test_index]\n",
    "\n",
    "    # Splitting the data in train and val sets\n",
    "    val_size = int(val_split * images.size)\n",
    "    val_split = val_size / dev_images.size\n",
    "    sss2 = StratifiedShuffleSplit(\n",
    "        n_splits=1, test_size=val_split, random_state=10)\n",
    "    sss2.get_n_splits(dev_images, dev_labels)\n",
    "    train_index, val_index = next(sss2.split(dev_images, dev_labels))\n",
    "\n",
    "    train_images = images[train_index]\n",
    "    train_labels = labels_int[train_index]\n",
    "\n",
    "    val_images = images[val_index]\n",
    "    val_labels = labels_int[val_index]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Train set:\", train_images.size)\n",
    "        # print(train_labels)\n",
    "        print(\"Val set:\", val_images.size)\n",
    "        # print(val_labels)\n",
    "        print(\"Test set:\", test_images.size)\n",
    "        # print(test_labels)\n",
    "\n",
    "    # Representing the sets as dictionaries\n",
    "    train_set = {\"X\": train_images, \"Y\": train_labels}\n",
    "    val_set = {\"X\": val_images, \"Y\": val_labels}\n",
    "    test_set = {\"X\": test_images, \"Y\": test_labels}\n",
    "\n",
    "    # Transforms\n",
    "    torchvision_transform_train = transforms.Compose([transforms.Resize((640, 640)),\n",
    "                                                      transforms.RandomHorizontalFlip(),\n",
    "                                                      transforms.RandomVerticalFlip(),\n",
    "                                                      transforms.ToTensor()])\n",
    "\n",
    "    # Datasets\n",
    "    train_dataset_unorm = TorchVisionDataset(\n",
    "        train_set, transform=torchvision_transform_train)\n",
    "\n",
    "    # Get training set stats\n",
    "    trainloader_unorm = torch.utils.data.DataLoader(\n",
    "        train_dataset_unorm, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    mean_train, std_train = get_dataset_stats(trainloader_unorm)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Statistics of training set\")\n",
    "        print(\"Mean:\", mean_train)\n",
    "        print(\"Std:\", std_train)\n",
    "\n",
    "    torchvision_transform = transforms.Compose([transforms.Resize((640, 640)),\n",
    "                                                transforms.RandomHorizontalFlip(), transforms.RandomVerticalFlip(),\n",
    "                                                transforms.ToTensor(),\n",
    "                                                transforms.Normalize(mean=mean_train, std=std_train)])\n",
    "\n",
    "    torchvision_transform_test = transforms.Compose([transforms.Resize((640, 640)),\n",
    "                                                     transforms.ToTensor(),\n",
    "                                                     transforms.Normalize(mean=mean_train, std=std_train)])\n",
    "\n",
    "    # Get the train/val/test loaders\n",
    "    train_dataset = TorchVisionDataset(\n",
    "        train_set, transform=torchvision_transform)\n",
    "    val_dataset = TorchVisionDataset(val_set, transform=torchvision_transform)\n",
    "    test_dataset = TorchVisionDataset(\n",
    "        test_set, transform=torchvision_transform_test)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    valloader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, num_workers=0)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate(net, trainloader, valloader, epochs, batch_size,\n",
    "                   learning_rate, best_model_path, device, verbose):\n",
    "    best_loss = 1e+20\n",
    "    for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "        # Loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()  # Loss function\n",
    "        optimizer = torch.optim.AdamW(net.parameters(), lr=learning_rate)\n",
    "        scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "        # Training Loop\n",
    "        train_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "        print(f'{20 + 1},  train loss: {train_loss / i:.3f},', end=' ')\n",
    "        scheduler.step()\n",
    "\n",
    "        val_loss = 0\n",
    "        # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(valloader, 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "            print(f'val loss: {val_loss / i:.3f}')\n",
    "\n",
    "            # Save best model\n",
    "            if val_loss < best_loss:\n",
    "                print(\"Saving model\")\n",
    "                torch.save(net.state_dict(), best_model_path)\n",
    "                best_loss = val_loss\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, testloader, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print(len(testloader))\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            print(\"images:\")\n",
    "            print(images[0].size())\n",
    "            print(images[0].permute(1,2,0))\n",
    "            image = torch.Tensor.cpu(images[0])\n",
    "            plt.imshow(image.permute(1,2,0))\n",
    "            print(\"labels:\")\n",
    "            print(labels)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            print(\"predicted:\")\n",
    "            print(predicted)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "    print(\n",
    "        f'Accuracy of the network on the test images: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--learning_rate', type=float, default=1e-4, help='initial learning rate')\n",
    "    parser.add_argument('--batch_size', type=int, default=1, help='batch size,  number of images in each iteration during training')\n",
    "    parser.add_argument('--epochs', type=int, default=20, help='total epochs')\n",
    "    parser.add_argument('--val_split', type=float, default=0.2, help='val split')\n",
    "    parser.add_argument('--test_split', type=float, default=0.2, help='test split')\n",
    "    parser.add_argument('--best_model_path', type=str, default=\"best_model\", help='best model path')\n",
    "    parser.add_argument('--images_path', type=str, default=1e-4, help='path to images')\n",
    "    parser.add_argument('--verbose', type=bool, default=True, help='verbose debugging flag')\n",
    "    parser.add_argument('--transfer_learning', type=bool, default=True, help='transfer learning flag')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Check if GPU is available\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "    if args.verbose:\n",
    "      print(device)\n",
    "\n",
    "    trainloader, valloader, testloader = \\\n",
    "    get_data_loaders(args.images_path, args.val_split, args.test_split,\\\n",
    "                     batch_size=args.batch_size, verbose=args.verbose)\n",
    "\n",
    "\n",
    "    # Create our model\n",
    "    net = GarbageModel(3, (3,640,640), args.transfer_learning)\n",
    "    net.to(device)\n",
    "\n",
    "    train_validate(net, trainloader, valloader, args.epochs, args.batch_size,\\\n",
    "         args.learning_rate, args.best_model_path, device, args.verbose)\n",
    "\n",
    "    net.load_state_dict(torch.load(args.best_model_path))\n",
    "\n",
    "    test(net, testloader,device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
